---
phase: 07-ai-first-architecture
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - backend/app/ai/client.py
autonomous: true

user_setup:
  - service: anthropic
    why: "Claude API for document review with native PDF support"
    env_vars:
      - name: ANTHROPIC_API_KEY
        source: "Anthropic Console -> API Keys -> Create Key"

must_haves:
  truths:
    - "AI client uses Claude instead of Gemini"
    - "Client supports native PDF document input"
    - "Client supports async streaming responses"
    - "PDF passed as base64-encoded document type"
  artifacts:
    - path: "backend/app/ai/client.py"
      provides: "Anthropic Claude client with PDF and streaming"
      min_lines: 80
      contains: "AsyncAnthropic"
  key_links:
    - from: "backend/app/ai/client.py"
      to: "anthropic SDK"
      via: "AsyncAnthropic import"
      pattern: "from anthropic import AsyncAnthropic"
---

<objective>
Rewrite the AI client to use Claude with native PDF support and async streaming.

Purpose: Switch from Gemini to Claude (ARCH-03) and enable streaming responses for real-time UI updates. Claude's native PDF support provides both text extraction and visual understanding.

Output: New client.py with AsyncAnthropic client, PDF document support, and streaming generator.
</objective>

<execution_context>
@C:\Users\abelb\.claude/get-shit-done/workflows/execute-plan.md
@C:\Users\abelb\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/phases/07-ai-first-architecture/07-CONTEXT.md
@.planning/phases/07-ai-first-architecture/07-RESEARCH.md
@backend/app/ai/client.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Rewrite AI client for Claude with PDF and streaming</name>
  <files>backend/app/ai/client.py</files>
  <action>
Completely rewrite `backend/app/ai/client.py` to use Anthropic Claude instead of Google Gemini.

**Key changes:**
1. Replace `from google import genai` with `from anthropic import AsyncAnthropic`
2. Use `ANTHROPIC_API_KEY` environment variable instead of `GOOGLE_API_KEY`
3. Use model `claude-sonnet-4-5` (or configurable via `AI_MODEL` env var)
4. Implement native PDF document input (not rendered images)
5. Implement async streaming with `client.messages.stream()`

**Implementation:**

```python
"""
Anthropic Claude client wrapper with native PDF support and streaming.
Uses Claude for AI-powered document review with full PDF understanding.
"""
import base64
import os
from typing import AsyncGenerator, Optional

from anthropic import AsyncAnthropic


class AIClientError(Exception):
    """Base exception for AI client errors."""
    pass


class AIConfigurationError(AIClientError):
    """Raised when API key is missing or invalid."""
    pass


class AIClient:
    """
    Wrapper for Anthropic Claude API with native PDF and streaming support.

    Uses Claude's native PDF document type for full text + visual understanding.
    Supports async streaming for real-time response delivery.
    """

    DEFAULT_MODEL = "claude-sonnet-4-5"
    DEFAULT_MAX_TOKENS = 8192

    def __init__(self):
        """Initialize the AI client. API key validated on first use."""
        self._client: Optional[AsyncAnthropic] = None
        self._model = os.getenv("AI_MODEL", self.DEFAULT_MODEL)

    def _ensure_client(self) -> AsyncAnthropic:
        """Lazy initialization of Anthropic client."""
        if self._client is None:
            api_key = os.getenv("ANTHROPIC_API_KEY")

            if not api_key:
                raise AIConfigurationError(
                    "ANTHROPIC_API_KEY not set.\n"
                    "Get your API key from: https://console.anthropic.com/settings/keys"
                )

            self._client = AsyncAnthropic(api_key=api_key)
        return self._client

    async def review_document_stream(
        self,
        pdf_bytes: bytes,
        user_prompt: str,
        system_prompt: str,
        max_tokens: Optional[int] = None,
    ) -> AsyncGenerator[str, None]:
        """
        Stream document review using Claude's native PDF support.

        Args:
            pdf_bytes: Raw PDF file bytes
            user_prompt: User message with extraction JSON and document type
            system_prompt: System prompt with rules context
            max_tokens: Max response tokens (default: 8192)

        Yields:
            Text chunks as they're generated

        Raises:
            AIClientError: On API errors
            AIConfigurationError: If API key is missing
        """
        client = self._ensure_client()
        pdf_base64 = base64.standard_b64encode(pdf_bytes).decode("utf-8")

        try:
            async with client.messages.stream(
                model=self._model,
                max_tokens=max_tokens or self.DEFAULT_MAX_TOKENS,
                system=system_prompt,
                messages=[
                    {
                        "role": "user",
                        "content": [
                            {
                                "type": "document",
                                "source": {
                                    "type": "base64",
                                    "media_type": "application/pdf",
                                    "data": pdf_base64,
                                }
                            },
                            {
                                "type": "text",
                                "text": user_prompt,
                            }
                        ],
                    }
                ],
            ) as stream:
                async for text in stream.text_stream:
                    yield text

        except Exception as e:
            error_str = str(e).lower()

            if "invalid" in error_str and "key" in error_str:
                raise AIConfigurationError(f"Invalid API key: {e}") from e

            if "rate" in error_str or "quota" in error_str:
                raise AIClientError(f"Rate limit exceeded: {e}") from e

            raise AIClientError(f"API error: {e}") from e


# Singleton instance
_client: Optional[AIClient] = None


def get_ai_client() -> AIClient:
    """Get or create AI client singleton."""
    global _client
    if _client is None:
        _client = AIClient()
    return _client
```

**Key features:**
- Native PDF: `type: "document"` with `media_type: "application/pdf"` (not rendered images)
- Async streaming: `async with client.messages.stream()` + `async for text in stream.text_stream`
- Lazy initialization: API key validated on first use, not at import
- Singleton pattern: Shared client instance across requests
- Error handling: Distinguish configuration errors from API errors

**Dependencies:**
- Ensure `anthropic>=0.35.0` is in requirements (has native PDF support)
  </action>
  <verify>
- File exists with AsyncAnthropic import
- `review_document_stream` method exists and is async generator
- No references to Google/Gemini remain
- `python -c "from app.ai.client import get_ai_client; print('OK')"` succeeds
  </verify>
  <done>
- AI client rewritten for Claude with native PDF support
- Async streaming generator implemented
- Singleton pattern preserved
- Error handling for API key and rate limits
  </done>
</task>

<task type="auto">
  <name>Task 2: Update requirements with Anthropic SDK</name>
  <files>backend/requirements.txt</files>
  <action>
Update `backend/requirements.txt` to include Anthropic SDK and sse-starlette:

Add these lines (if not present):
```
anthropic>=0.35.0
sse-starlette>=1.6.0
```

Remove (if present):
```
google-genai
google-generativeai
```

Keep all other dependencies unchanged.
  </action>
  <verify>
- requirements.txt contains `anthropic>=0.35.0`
- requirements.txt contains `sse-starlette`
- No Google AI SDK references (unless needed for other features)
  </verify>
  <done>
- Requirements updated with Anthropic SDK
- sse-starlette added for streaming endpoint
  </done>
</task>

</tasks>

<verification>
1. `python -c "from app.ai.client import AIClient, get_ai_client; print('OK')"` succeeds
2. client.py contains `AsyncAnthropic` and `review_document_stream`
3. requirements.txt has `anthropic>=0.35.0`
4. No Gemini/Google AI imports in client.py
</verification>

<success_criteria>
- AI client uses Anthropic Claude SDK
- Native PDF document input supported
- Async streaming generator implemented
- Requirements updated with anthropic SDK
</success_criteria>

<output>
After completion, create `.planning/phases/07-ai-first-architecture/07-02-SUMMARY.md`
</output>
