---
phase: 04-ai-verification
plan: 02
type: execute
wave: 2
depends_on: ["04-01"]
files_modified:
  - backend/app/ai/analyzer.py
  - backend/app/ai/router.py
  - backend/app/checks/models.py
  - backend/app/main.py
  - backend/app/ai/__init__.py
autonomous: true

must_haves:
  truths:
    - "AI analysis runs on all pages concurrently (3-5 at a time)"
    - "Failed pages show timeout message in results"
    - "Extraction data feeds AI alongside page images"
    - "CheckIssue model supports AI-specific fields"
  artifacts:
    - path: "backend/app/ai/analyzer.py"
      provides: "Document analyzer orchestrating per-page AI calls"
      exports: ["DocumentAnalyzer", "analyze_document"]
    - path: "backend/app/ai/router.py"
      provides: "REST API endpoint for AI analysis"
      exports: ["router"]
    - path: "backend/app/checks/models.py"
      provides: "Extended CheckIssue with AI fields"
      contains: "ai_verified"
  key_links:
    - from: "backend/app/ai/analyzer.py"
      to: "backend/app/ai/client.py"
      via: "AIClient.analyze_page calls"
      pattern: "client\\.analyze_page"
    - from: "backend/app/ai/router.py"
      to: "backend/app/ai/analyzer.py"
      via: "analyze_document call"
      pattern: "analyze_document"
    - from: "backend/app/main.py"
      to: "backend/app/ai/router.py"
      via: "router registration"
      pattern: "include_router.*ai"
---

<objective>
Create document analyzer with concurrent page processing and REST API endpoint.

Purpose: Orchestrates AI analysis across all PDF pages, handles timeouts gracefully, and exposes analysis via API endpoint.

Output: POST /api/ai/analyze endpoint that processes PDF and returns structured AI findings.
</objective>

<execution_context>
@C:\Users\abelb\.claude/get-shit-done/workflows/execute-plan.md
@C:\Users\abelb\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/LEARNINGS.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-ai-verification/04-CONTEXT.md
@.planning/phases/04-ai-verification/04-RESEARCH.md
@.planning/phases/04-ai-verification/04-01-SUMMARY.md
@backend/app/checks/models.py
@backend/app/checks/router.py
@backend/app/main.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Extend CheckIssue model with AI fields</name>
  <files>backend/app/checks/models.py</files>
  <action>
Add AI-specific fields to CheckIssue model per CONTEXT.md decisions.

Add these optional fields to CheckIssue:
```python
# AI analysis fields
ai_verified: bool = False  # True if this came from AI analysis
ai_confidence: Optional[Literal["high", "medium", "low"]] = None
ai_reasoning: Optional[str] = None  # One sentence, only for non-obvious findings
```

These fields allow the frontend to:
- Display confidence indicator (icon + tooltip) for medium/low confidence
- Show expandable reasoning section
- Style low-confidence findings with muted appearance

Keep existing fields unchanged. Pydantic v1 pattern (class Config).
  </action>
  <verify>
```bash
cd backend && python -c "
from app.checks.models import CheckIssue
issue = CheckIssue(
    rule_id='test', rule_name='Test', severity='warning',
    message='AI found issue', pages=[1],
    ai_verified=True, ai_confidence='medium', ai_reasoning='Appears blurry'
)
print(f'AI verified: {issue.ai_verified}')
print(f'Confidence: {issue.ai_confidence}')
print(f'Reasoning: {issue.ai_reasoning}')
"
```
  </verify>
  <done>CheckIssue has ai_verified, ai_confidence, ai_reasoning fields</done>
</task>

<task type="auto">
  <name>Task 2: Create document analyzer with concurrent page processing</name>
  <files>backend/app/ai/analyzer.py</files>
  <action>
Create document analyzer that processes pages concurrently.

**analyzer.py:**
- `DocumentAnalyzer` class:
  - Constructor takes pdf_path, extraction (ExtractionResult), document_type
  - `analyze() -> DocumentAnalysisResult` method
  - Uses asyncio.Semaphore(5) for 3-5 concurrent page analysis
  - For each page:
    1. Render page to base64 (72 DPI)
    2. Generate checklist from merged rules
    3. Build prompt with checklist + extraction summary for that page
    4. Call AIClient.analyze_page()
    5. Parse response into PageAnalysisResult
  - 30-second timeout per page (asyncio.wait_for)
  - On timeout: PageAnalysisResult with error="Page X timed out"
  - On API error after retries: PageAnalysisResult with error message

- `analyze_document(pdf_path, extraction, document_type) -> DocumentAnalysisResult` function:
  - Creates analyzer and calls analyze()
  - Measures total duration in milliseconds

- Extraction summary per page includes:
  - Page dimensions and margins
  - Fonts found on that page
  - Images on that page with DPI
  - Text snippets (first 500 chars)

Add exports to __init__.py: DocumentAnalyzer, analyze_document
  </action>
  <verify>
```bash
cd backend && python -c "
from app.ai.analyzer import DocumentAnalyzer, analyze_document
import inspect
# Check analyze_document signature
sig = inspect.signature(analyze_document)
params = list(sig.parameters.keys())
print(f'analyze_document params: {params}')
print(f'Has pdf_path: {\"pdf_path\" in params}')
print(f'Has extraction: {\"extraction\" in params}')
"
```
  </verify>
  <done>DocumentAnalyzer processes pages concurrently with 30s timeout per page</done>
</task>

<task type="auto">
  <name>Task 3: Create AI analysis API endpoint</name>
  <files>backend/app/ai/router.py, backend/app/main.py, backend/app/ai/__init__.py</files>
  <action>
Create REST API router for AI analysis.

**router.py:**
```python
from fastapi import APIRouter, HTTPException, UploadFile, File, Form
from typing import Optional
import tempfile
import os

from app.models.extraction import ExtractionResult
from app.config.service import DocumentTypeId
from .analyzer import analyze_document
from .schemas import DocumentAnalysisResult

router = APIRouter(prefix="/api/ai", tags=["ai"])

@router.post("/analyze", response_model=DocumentAnalysisResult)
async def analyze_pdf(
    document_type: DocumentTypeId = Form(...),
    extraction: str = Form(...),  # JSON string of ExtractionResult
    file: UploadFile = File(...),
) -> DocumentAnalysisResult:
    """
    Run AI analysis on uploaded PDF.

    Receives PDF file and extraction data, returns AI findings.
    """
    import json
    from pydantic import parse_obj_as

    # Parse extraction from JSON
    extraction_data = ExtractionResult.parse_raw(extraction)

    # Save uploaded file to temp location
    with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp:
        content = await file.read()
        tmp.write(content)
        tmp_path = tmp.name

    try:
        result = await analyze_document(tmp_path, extraction_data, document_type)
        return result
    finally:
        os.unlink(tmp_path)
```

**main.py changes:**
- Import ai router: `from app.ai.router import router as ai_router`
- Register: `app.include_router(ai_router)`

**__init__.py:**
- Add router to exports

Note: Endpoint receives multipart form with PDF file, document_type, and extraction JSON.
This avoids re-extracting - reuses existing extraction data.
  </action>
  <verify>
```bash
cd backend && python -c "
from fastapi.testclient import TestClient
from app.main import app
client = TestClient(app)
# Check route exists
routes = [r.path for r in app.routes]
print(f'Has /api/ai/analyze: {\"/api/ai/analyze\" in str(routes)}')
"
```
  </verify>
  <done>POST /api/ai/analyze endpoint registered and accepts PDF + extraction data</done>
</task>

</tasks>

<verification>
AI analysis endpoint accessible and CheckIssue extended:
```bash
cd backend && python -c "
from app.checks.models import CheckIssue
from app.ai import DocumentAnalyzer, analyze_document, router
from app.ai.schemas import DocumentAnalysisResult

# Verify AI fields on CheckIssue
issue = CheckIssue(
    rule_id='ai_test', rule_name='AI Test', severity='warning',
    message='Test', pages=[1], ai_verified=True, ai_confidence='low'
)
print(f'CheckIssue AI fields work: {issue.ai_verified}')

# Verify analyzer exists
print(f'DocumentAnalyzer exists: {DocumentAnalyzer is not None}')
print(f'analyze_document exists: {analyze_document is not None}')
print('All Plan 02 components verified')
"
```
</verification>

<success_criteria>
1. CheckIssue model has ai_verified, ai_confidence, ai_reasoning fields
2. DocumentAnalyzer processes pages with 3-5 concurrent limit
3. 30-second timeout per page with graceful error handling
4. POST /api/ai/analyze endpoint accepts PDF and extraction data
5. Results include per-page findings and document summary
</success_criteria>

<output>
After completion, create `.planning/phases/04-ai-verification/04-02-SUMMARY.md`
</output>
